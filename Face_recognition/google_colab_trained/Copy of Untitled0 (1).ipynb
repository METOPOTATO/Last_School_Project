{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBcstlJVZJAd","executionInfo":{"status":"ok","timestamp":1607326263540,"user_tz":-420,"elapsed":821,"user":{"displayName":"linh bui","photoUrl":"","userId":"12979780239569612822"}},"outputId":"2911a8a9-6b16-4981-f580-3858cfb33acc"},"source":["from google.colab import drive\n","import os\n","\n","drive.mount(\"/content/drive\")\n","path = \"/content/drive/My Drive/Facial_expression_2/\"\n","os.chdir(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rdpYvRAHZM6l"},"source":["import tensorflow as tf\n","import keras\n","import numpy as np \n","import cv2\n","from sklearn.model_selection import train_test_split\n","from keras.applications import VGG16,VGG19\n","from keras.layers import Dense, Flatten,Dropout\n","from keras.models import Model,Sequential\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","import pickle\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9g_zta4a5b6"},"source":["def save_pickle(obj, file_path):\n","  with open(file_path, 'wb') as f:\n","    pickle.dump(obj,f)\n","\n","def load_pickle(file_path):\n","  with open(file_path,'rb') as f:\n","    obj = pickle.load(f)\n","  return obj"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTBfIf6za7EC"},"source":["IMG_SIZE = (224,224)\n","IMG_SHAPE = (224,224,3)\n","BATCH_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HwQUxI6vFqbd"},"source":["# IMG_SIZE = (48,48)\n","# IMG_SHAPE = (48,48,3)\n","# BATCH_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QlBQPFtC4iq"},"source":["\n","# count = 0\n","# path_train = path + 'Data/train'\n","# # for file in os.listdir(path_train):\n","# file = 'sad'\n","# data = []\n","# labels = []\n","# for img in os.listdir(path_train +'/'+file):\n","#   try:\n","#     image= cv2.imread(path_train +'/'+file+'/'+img)\n","\n","#     data.append(image)\n","#     labels.append(file)\n","#     print(count )\n","#     count+=1\n","#   except:\n","#     print('error')\n","\n","# save_pickle(data,'pkl_48/data_train_'+ file +'.pkl')\n","# save_pickle(labels,'pkl_48/labels_train_' + file + '.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9BVeGI2ZF6vl"},"source":["# count = 0\n","# path_val = path + 'Data/validation/'\n","# data = []\n","# labels = []\n","# for file in os.listdir(path_val):\n","#   for img in os.listdir(path_val +'/'+file):\n","#     try:\n","#       image= cv2.imread(path_val +'/'+file+'/'+img)\n","#       data.append(image)\n","#       labels.append(file)\n","#       print(count )\n","#       count+=1\n","#     except:\n","#       print('error')\n","\n","# save_pickle(data,'pkl_48/data_val.pkl')\n","# save_pickle(labels,'pkl_48/labels.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8GTeb8BiKg_O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607326395756,"user_tz":-420,"elapsed":132986,"user":{"displayName":"linh bui","photoUrl":"","userId":"12979780239569612822"}},"outputId":"7bd85074-c23f-4a1f-c2ae-589d650fe71e"},"source":["path_train = path + 'Data/train'\n","X_train = []\n","y_train = []\n","for file in ('angry','fear','happy','neutral','sad','surprise'):\n","  X = load_pickle('pkl_224/data_train_'+ file +'.pkl')\n","  y = load_pickle('pkl_224/labels_train_'+ file +'.pkl')\n","  print(file + str(len(X)) )\n","  X_train.extend(X)\n","  y_train.extend(y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["angry3999\n","fear4103\n","happy7173\n","neutral4992\n","sad4938\n","surprise3205\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1fIztE-BamQy"},"source":["X_val = load_pickle('pkl_224/data_val.pkl')\n","y_val = load_pickle('pkl_224/labels_val.pkl')\n","\n","X_val6 = []\n","y_val6 = []\n","for num,i in enumerate(y_val):\n","  if i == 'disgust':\n","    continue \n","  X_val6.append(X_val[num])\n","  y_val6.append(y_val[num])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-q0pPLUkp8Ar","executionInfo":{"status":"ok","timestamp":1607326426520,"user_tz":-420,"elapsed":163738,"user":{"displayName":"linh bui","photoUrl":"","userId":"12979780239569612822"}},"outputId":"91ef6368-2e5c-456b-c6aa-cc91d18f5e75"},"source":["print(len(y_val))\n","print(len(y_val6))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7070\n","6959\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pf0WeFAUtihP"},"source":["for x in X_train:\n","  x = cv2.dnn.blobFromImage(x, 1.0, IMG_SIZE, [104, 117, 123], False, False)\n","  mean,std =  x.mean(), x.std()\n","  x = (x - mean) / std\n","  \n","for x in X_val6:\n","  x = cv2.dnn.blobFromImage(x, 1.0, IMG_SIZE, [104, 117, 123], False, False)\n","  mean,std =  x.mean(), x.std()\n","  x = (x - mean) / std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qYLYzwHhiid"},"source":["from sklearn.preprocessing import LabelEncoder\n","encode = LabelEncoder()\n","encode.fit(y_train)\n","y_train = encode.transform(y_train)\n","y_val6 = encode.transform(y_val6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKVZN8NfYF6R"},"source":["X_train = np.asarray(X_train)\n","y_train = np.asarray(y_train)\n","X_val6 = np.asarray(X_val6)\n","y_val6 = np.asarray(y_val6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F05T1mdBbApa","executionInfo":{"status":"ok","timestamp":1607326470466,"user_tz":-420,"elapsed":207666,"user":{"displayName":"linh bui","photoUrl":"","userId":"12979780239569612822"}},"outputId":"20dd2d6a-ff54-4660-d47d-ee8f162ac0ae"},"source":["VGG_model = VGG19(\n","      include_top = False,\n","      weights='imagenet',\n","      input_shape = IMG_SHAPE\n","  )\n","model = Sequential()\n","\n","for layer in VGG_model.layers:\n","  layer.trainable = False\n","  model.add(layer)\n","\n","model.add(Flatten())\n","model.add(Dense(2048*2, activation='relu') )\n","model.add(Dense(2048, activation='relu') )\n","# model.add(Dropout(0.2))\n","model.add(Dense(1024, activation='relu') )\n","model.add(Dense(7, activation='softmax') )\n","\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4096)              102764544 \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2048)              8390656   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 7)                 7175      \n","=================================================================\n","Total params: 133,284,935\n","Trainable params: 113,260,551\n","Non-trainable params: 20,024,384\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Miko4SsUy1mc"},"source":["# aug = ImageDataGenerator(\n","#     rotation_range=20,\n","# \t\tzoom_range=0.15,\n","# \t\twidth_shift_range=0.2,\n","# \t\theight_shift_range=0.2,\n","# \t\tshear_range=0.15,\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dt-cYA_53MbL"},"source":["# from tensorflow.keras.callbacks import ModelCheckpoint\n","# checkpoint_path = 'checkpoints/'\n","# epochs = 10\n","\n","# callbacks = [\n","#     keras.callbacks.ModelCheckpoint(\n","#       filepath=checkpoint_path,\n","#       save_freq='epoch',\n","#       save_best_only=True,\n","#       verbose=1\n","#     ),\n","# ]\n","# model.compile(\n","#     optimizer=keras.optimizers.Adam(1e-3),\n","#     loss=\"sparse_categorical_crossentropy\",\n","#     metrics=[\"accuracy\"],\n","# )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoBXnuB951DK"},"source":["# model.fit(x =aug.flow(X_train,y_train,batch_size=64),\n","#           epochs=10,     \n","#           validation_data=(X_val,y_val ),\n","#           callbacks=[checkpoint])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbC_yYak39ei","executionInfo":{"status":"ok","timestamp":1607330264033,"user_tz":-420,"elapsed":4001216,"user":{"displayName":"linh bui","photoUrl":"","userId":"12979780239569612822"}},"outputId":"deced20f-d0af-45e8-fb10-adcdedbf1f2b"},"source":["epochs = 20\n","checkpoint_path = 'checkpoints/'\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","      filepath=checkpoint_path,\n","      save_freq='epoch',\n","      monitor='val_accuracy',\n","      save_best_only=True,\n","      verbose=1\n","    ),\n","]\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-3),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","\n","model.fit(\n","    X_train,\n","    y_train,\n","    epochs=epochs,\n","    validation_data=(X_val6,y_val6),\n","    callbacks=callbacks\n",")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","888/888 [==============================] - ETA: 0s - loss: 3.0529 - accuracy: 0.4890\n","Epoch 00001: val_accuracy improved from -inf to 0.51631, saving model to checkpoints/\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: checkpoints/assets\n","888/888 [==============================] - 198s 223ms/step - loss: 3.0529 - accuracy: 0.4890 - val_loss: 1.2689 - val_accuracy: 0.5163\n","Epoch 2/20\n","888/888 [==============================] - ETA: 0s - loss: 1.0295 - accuracy: 0.6251\n","Epoch 00002: val_accuracy improved from 0.51631 to 0.56373, saving model to checkpoints/\n","INFO:tensorflow:Assets written to: checkpoints/assets\n","888/888 [==============================] - 197s 222ms/step - loss: 1.0295 - accuracy: 0.6251 - val_loss: 1.2087 - val_accuracy: 0.5637\n","Epoch 3/20\n","888/888 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.7137\n","Epoch 00003: val_accuracy improved from 0.56373 to 0.58270, saving model to checkpoints/\n","INFO:tensorflow:Assets written to: checkpoints/assets\n","888/888 [==============================] - 198s 223ms/step - loss: 0.8011 - accuracy: 0.7137 - val_loss: 1.1836 - val_accuracy: 0.5827\n","Epoch 4/20\n","888/888 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.7888\n","Epoch 00004: val_accuracy did not improve from 0.58270\n","888/888 [==============================] - 186s 209ms/step - loss: 0.5913 - accuracy: 0.7888 - val_loss: 1.3036 - val_accuracy: 0.5788\n","Epoch 5/20\n","888/888 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8427\n","Epoch 00005: val_accuracy improved from 0.58270 to 0.58543, saving model to checkpoints/\n","INFO:tensorflow:Assets written to: checkpoints/assets\n","888/888 [==============================] - 197s 222ms/step - loss: 0.4642 - accuracy: 0.8427 - val_loss: 1.5206 - val_accuracy: 0.5854\n","Epoch 6/20\n","888/888 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8773\n","Epoch 00006: val_accuracy did not improve from 0.58543\n","888/888 [==============================] - 186s 209ms/step - loss: 0.3626 - accuracy: 0.8773 - val_loss: 1.7883 - val_accuracy: 0.5798\n","Epoch 7/20\n","888/888 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.9007\n","Epoch 00007: val_accuracy improved from 0.58543 to 0.58873, saving model to checkpoints/\n","INFO:tensorflow:Assets written to: checkpoints/assets\n","888/888 [==============================] - 197s 222ms/step - loss: 0.2936 - accuracy: 0.9007 - val_loss: 1.9633 - val_accuracy: 0.5887\n","Epoch 8/20\n","888/888 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9213\n","Epoch 00008: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 186s 209ms/step - loss: 0.2461 - accuracy: 0.9213 - val_loss: 2.1530 - val_accuracy: 0.5815\n","Epoch 9/20\n","888/888 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9339\n","Epoch 00009: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 185s 209ms/step - loss: 0.2070 - accuracy: 0.9339 - val_loss: 2.0713 - val_accuracy: 0.5861\n","Epoch 10/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9407\n","Epoch 00010: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 186s 209ms/step - loss: 0.1954 - accuracy: 0.9407 - val_loss: 2.3216 - val_accuracy: 0.5708\n","Epoch 11/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9500\n","Epoch 00011: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 186s 209ms/step - loss: 0.1671 - accuracy: 0.9500 - val_loss: 2.2411 - val_accuracy: 0.5800\n","Epoch 12/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9511\n","Epoch 00012: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 185s 209ms/step - loss: 0.1650 - accuracy: 0.9511 - val_loss: 2.1566 - val_accuracy: 0.5752\n","Epoch 13/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9577\n","Epoch 00013: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 185s 208ms/step - loss: 0.1466 - accuracy: 0.9577 - val_loss: 2.5174 - val_accuracy: 0.5856\n","Epoch 14/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9611\n","Epoch 00014: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 185s 209ms/step - loss: 0.1303 - accuracy: 0.9611 - val_loss: 2.5998 - val_accuracy: 0.5877\n","Epoch 15/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9616\n","Epoch 00015: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 185s 209ms/step - loss: 0.1300 - accuracy: 0.9616 - val_loss: 2.7907 - val_accuracy: 0.5814\n","Epoch 16/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9666\n","Epoch 00016: val_accuracy did not improve from 0.58873\n","888/888 [==============================] - 186s 209ms/step - loss: 0.1200 - accuracy: 0.9666 - val_loss: 2.6517 - val_accuracy: 0.5844\n","Epoch 17/20\n","888/888 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9724\n","Epoch 00017: val_accuracy improved from 0.58873 to 0.59534, saving model to checkpoints/\n","INFO:tensorflow:Assets written to: checkpoints/assets\n","888/888 [==============================] - 197s 222ms/step - loss: 0.0981 - accuracy: 0.9724 - val_loss: 2.9512 - val_accuracy: 0.5953\n","Epoch 18/20\n","888/888 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9723\n","Epoch 00018: val_accuracy did not improve from 0.59534\n","888/888 [==============================] - 185s 209ms/step - loss: 0.0970 - accuracy: 0.9723 - val_loss: 2.8256 - val_accuracy: 0.5813\n","Epoch 19/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9685\n","Epoch 00019: val_accuracy did not improve from 0.59534\n","888/888 [==============================] - 185s 208ms/step - loss: 0.1139 - accuracy: 0.9685 - val_loss: 3.2352 - val_accuracy: 0.5748\n","Epoch 20/20\n","888/888 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9703\n","Epoch 00020: val_accuracy did not improve from 0.59534\n","888/888 [==============================] - 186s 209ms/step - loss: 0.1067 - accuracy: 0.9703 - val_loss: 2.6599 - val_accuracy: 0.5788\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb2628ecba8>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Naziay_nP6F1"},"source":["model=keras.models.load_model('checkpoints/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1O4r864bRSMO"},"source":["model.save('face_expression_59.53.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZQ7ZqP4TP4d"},"source":[""],"execution_count":null,"outputs":[]}]}